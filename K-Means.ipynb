{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from sklearn.cluster import KMeans\n",
    "from functools import reduce\n",
    "from build_sentence_corp import extract_sent\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import random\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_size = 300\n",
    "embedding_path = 'models/word2vec/GoogleNews-vectors-negative300.bin'\n",
    "embedding = gensim.models.KeyedVectors.load_word2vec_format(embedding_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocab(sentence_dir):\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    vocab_count = {}\n",
    "    for sent in sentence_dir:\n",
    "        for word in sent.split():\n",
    "            word = word.lower().translate(table).strip()\n",
    "            if word in vocab_count:\n",
    "                vocab_count[word] += 1\n",
    "            else:\n",
    "                vocab_count[word] = 1\n",
    "        \n",
    "    vocab = set()\n",
    "    k = 10    \n",
    "    for key, val in vocab_count.items():\n",
    "        if val >= k and key not in stopwords.words('english'):\n",
    "            vocab.add(key)\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sent(path, regex):\n",
    "    review_dir = []\n",
    "    for file in os.listdir(path):\n",
    "        with open(path+file) as f:\n",
    "            txt = f.read()\n",
    "            reviews = re.findall(regex, txt)\n",
    "        review_dir += reviews\n",
    "    \n",
    "    sentence_dir = []\n",
    "    for review in review_dir:\n",
    "        sentences = nltk.sent_tokenize(review)\n",
    "        sentence_dir += sentences\n",
    "        \n",
    "    return sentence_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeT(words):\n",
    "    matrix = np.empty((0, embedding_vector_size))\n",
    "    for w in words:\n",
    "        try:\n",
    "            matrix = np.vstack((matrix, embedding[w]))\n",
    "        except:\n",
    "            pass\n",
    "    print(matrix.shape)\n",
    "    kmeans = KMeans(n_clusters=14, random_state=0).fit(matrix)\n",
    "    return kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = './data/TripAdvisor/Texts/'\n",
    "regex = r\"<Content>(.*)\\n<Date>\" \n",
    "sentence_dir = extract_sent(text_path, regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2167783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = generate_vocab(sentence_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = initializeT(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_T = open('T_matrix.pickle', 'wb')\n",
    "pickle.dump(kmeans.cluster_centers_, pickle_T)\n",
    "pickle_T.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('T_matrix.pickle', 'rb')\n",
    "centers = pickle.load(pickle_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
